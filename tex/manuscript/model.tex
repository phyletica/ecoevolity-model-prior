Here we provide a summary of the model implemented in \ecoevolity; please see
\citet{Oaks2018ecoevolity} and \citet{Oaks2019codemog} for a full description.

Our model allows for an arbitrary number of two types of temporal comparisons:
\begin{enumerate}
    \item A population that experienced a change from effective population size
        \epopsize[\rootpopindex]
        to effective size
        \epopsize[\descendantpopindex{}]
        at time \comparisonetime in the past.
        We will refer to this as a \emph{demographic comparison},
        and refer to the population before and after the change in population
        size as ``ancestral'' and ``descendant'', respectively.
    \item A population that diverged at time \comparisonetime in the past into
        two descendant populations, each with unique effective population
        sizes.
        We will refer to this as a \emph{divergence comparison}.
\end{enumerate}
For simplicity, we will use terminology related to the timing of divergences
among divergence comparions.
However, all of the theory discussed below also applies to demographic
comparisons.

The primary goal is to infer the temporal clustering of divergences across
\ncomparisons comparisons.
At one extreme, all \ncomparisons could have diverged at the same time,
and at the other extreme, all \ncomparisons diverged independently.
This presents a model-choice problem, where the number of possible models
is the number of ways we can assign \ncomparisons comparisons to
$1, 2,  \ldots, \ncomparisons$ divergence times
\citep[the Bell number;][]{Bell1934}.
Below, we use \etimesets to represent the partitioning of comparisons to
divergence events, which we will also refer to as an ``divergence model,'' and
\etimes to represent the unique divergence times within \etimesets.

\subsection{Dirichlet-process (DP) prior}

\begin{linenomath}
\citet{Oaks2018ecoevolity} treated the number of divergence events and the
assignment of comparisons to those events as random variables under a Dirichlet
process \citep{Ferguson1973, Antoniak1974}.
The concentration parameter, \concentration, controls how clustered the
Dirichlet process is, and determines the probability of all possible \etimesets
(i.e., all possible set partitions of \ncomparisons comparisons).
To get these probabilities, we can assign comparisons to divergence events one
at a time, following a simple rule.
When assigning the $i^{th}$ comparison, we assign it to its own event
(i.e., a new divergence event with a unique time) with probability
\begin{equation}
    \frac{\concentration}{\concentration + i - 1},
    \label{eq:dpnewcat}
\end{equation}
or we assign it to an existing event $x$ with probability
\begin{equation}
    \frac{n_x}{\concentration + i - 1}.
    \label{eq:dpexistingcat}
\end{equation}
where $n_x$ is the number of comparisons already assigned to event $x$.
\end{linenomath}

\subsection{Pitman-Yor-process (PYP) prior}

\begin{linenomath}
\citet{PitmanYor1997} generalized the Dirichlet process by adding a
``discount'' parameter (\discount) that can take values from 0--1.
The rule governing the PYP is very similar to the DP.
When assigning the $i^{th}$ comparison, we assign it to its own event
with probability
\begin{equation}
    \frac{\concentration + \nexistingcats \discount}{\concentration + i - 1},
    \label{eq:pypnewcat}
\end{equation}
where \nexistingcats is the number of events that currently exist (i.e., that have at
least one comparison assigned to it).
Alternatively, we assign it to an existing event $x$ with probability
\begin{equation}
    \frac{n_x - \discount}{\concentration + i -1}.
    \label{eq:pypexistingcat}
\end{equation}
Notice, when $\discount = 0$, the PYP is equivalent to the DP.
\end{linenomath}

\subsection{Weighted-uniform prior}
We have also implemented a uniform prior over divergence models, where we can
assume \emph{a priori} that every possible divergence model (\etimesets) is
equally probable.
Furthermore, we added a ``split weight'' parameter, which we denote as
\splitweight, to provide flexibility on the prior probabilities of
models with different numbers of events.
For a given model with \nevents divergence events, the relative probability
of each model with $\nevents + 1$ events is \splitweight,
and the relative probability of each model with $\nevents - 1$ events is
$\frac{1}{\splitweight}$.
More generally, the relative probability of each model with
$\nevents + n$
events is
$\splitweight{}^n$,
and the relative probability of each model with
$\nevents - n$
events is
$\frac{1}{\splitweight{}^n}$.
When $\splitweight = 1$, all divergence models are equally probable.

\subsection{Approximating the posterior with MCMC}

We use Markov chain Monte Carlo (MCMC) algorithms to sample from
the joint posterior distribution of the divergence model (\etimesets),
divergence times (\etimes), effective population sizes, and
any mutation rate or substitution parameters
\cite{Oaks2018ecoevolity,Oaks2019codemog}.
Because \etimesets can differ in the number of divergence-time parameters, we
need to use trans-dimensional MCMC algorithms to sample over all possbile
divergence models.

Under the PYP, and the special case of the DP, the order of the comparisons
does not affect the probability of the model.
In other words, divergence models (\etimesets) that share the same integer
partition (i.e., the same number of events with the same number of comparisons
assigned to them) are equally probable.
Hence, the comparisons are exchangeable under the PYP and DP priors.
This allows us to use the Gibbs sampling algorithm (Algorithm 8) of
\citet{Neal2000} to update the \etimesets during the MCMC chain.

Unlike the PYP and DP, where divergence events with the same
integer partition were equally probably, under the
WU prior, divergence events that share the same number of events (\nevents) are
equally probable.
This means that the comparisons are not exchangeable under the WU prior, and
thus Gibbs sampling will not work to sample \etimesets under the WU prior.
Instead we use reversible-jump MCMC moves under the WU prior.

\subsubsection{reversible-jump MCMC}
Layout the rjMCMC moves here \ldots
